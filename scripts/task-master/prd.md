Perfect. I’ll now compile a full, production-grade PRD in Markdown format for the PaperMage reimplementation using the Docling stack. It will integrate every finding from Prompts #1–#6, including detailed GitHub file references, Hebrew/RTL support mechanisms, docling-serve patterns, and complete architecture/testing/deployment documentation.

I’ll let you know as soon as the full PRD is ready for your review.

# Executive Summary

PaperMage is a research prototype toolkit for analyzing scientific PDF documents, offering a unified representation of text and layout through a `Document` class with multiple hierarchical layers (pages, rows, tokens, etc.) ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,words%27%2C%20%27sentences%27%2C%20%27blocks%27%2C%20%27vila_entities%27%2C%20%27titles)). Its pipeline parses PDF content (via PDFPlumber) and applies computer vision/NLP models (e.g. the I-VILA model for document layout) to identify structural elements like titles, sections, figures, tables, and more ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,MIT%20License%20utility)) ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=%27headers%27%2C%20%27footers%27%2C%20%27footnotes%27%2C%20%27symbols%27%2C%20%27images%27%2C,metadata%27%2C%20%27entities%27%2C%20%27relations)). The goal of this project is to reimplement PaperMage’s functionality on the modern **Docling** stack – a suite of IBM Research open-source libraries (docling, docling-core, docling-parse, docling-serve) designed for efficient, multilingual document parsing ([Docling Project · GitHub](https://github.com/docling-project#:~:text=%2A%20docling%20%20,generation%20for%20RAG%2C%20finetuning%2C%20etc)). This migration aims to preserve **all features and output formats of PaperMage** while improving performance and maintainability. A critical objective is to add robust support for **Hebrew and other right-to-left (RTL)** scripts, ensuring text order and layout are handled correctly for those languages – an area not fully addressed in the original PaperMage.
Docling project by IBM Research has since emerged as a powerful unified document parsing library. Docling offers advanced PDF understanding (layout analysis, reading order, table structure, figure detection, etc.) and a unified DoclingDocument representation with lossless JSON export​
github.com
​
github.com
. Crucially, Docling-Parse v3.3.0+ introduced built-in bidirectional (bidi) text support for RTL languages​
github.com
, eliminating the need for our custom RTL handling. 

Docling provides modular components for document understanding: **docling-parse** handles low-level PDF text and image extraction with coordinates ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=Simple%20package%20to%20extract%20text%2C,extracted%20paths%20and%20bitmap%20resources)), **docling-core** defines a unified `DoclingDocument` data model (using Pydantic) for structured content ([GitHub - docling-project/docling-core: A python library to define and validate data types in Docling.](https://github.com/DS4SD/docling-core#:~:text=,for%20the%20full%20JSON%20schema)), and **docling-serve** offers FastAPI-based service wrappers for processing documents at scale ([Docling Project · GitHub](https://github.com/docling-project#:~:text=If%20it%20has%20to%20do,API%20and%20distribute%20large%20jobs)) this serve as a refference to a custom FastApi server or as a base line to this project FastAPI server. By leveraging these, the reimplementation (dubbed "PaperMage-Docling") will replace PaperMage’s custom PDF parsing and data structures with Docling’s standardized pipeline. The new system will ingest PDFs and produce a **JSON output identical to PaperMage’s** (down to field names and hierarchy) for compatibility ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=import%20json%20with%20open%28%27filename,to_json%28%29%2C%20f_out%2C%20indent%3D4)). Internally, however, it will utilize Docling’s high-performance parsing (including char/word/line extraction, reading order logic, and image handling) and validated data schemas. This ensures that the rich multilayer representation (e.g. text spans with bounding boxes for each entity ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=PaperMage%27s%20%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D1%83%D0%B5%D1%82%20%D0%B4%D0%B2%D0%B5%20%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5,%D0%B4%D0%B0%D0%B6%D0%B5%20%D0%BD%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%80%D0%B0%D0%B7%D0%BB%D0%B8%D1%87%D0%B8%D1%8F%20%D0%B2%20%D0%BC%D0%B0%D0%BA%D0%B5%D1%82%D0%B5))) is preserved, while gaining improvements such as built-in table structure recognition and future integration with GenAI tools ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=,gapped%20environments)).

In summary, this PRD outlines how each feature of PaperMage will be **mapped to an equivalent in the Docling stack** or reimplemented as needed. It details functional requirements (one-to-one correspondence between PaperMage capabilities and Docling-based implementations), non-functional goals (performance, containerized deployment, multilingual fidelity), system architecture (file layout and module design), and a step-by-step plan for RTL support. The end result will be a **drop-in replacement** for PaperMage’s core library and service: it will meet all prior use-case expectations (producing the same layers of output for scientific PDFs ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,words%27%2C%20%27sentences%27%2C%20%27blocks%27%2C%20%27vila_entities%27%2C%20%27titles))) while being easier to maintain and extend. The document that follows enumerates these requirements and design decisions in detail, ensuring the new PaperMage-Docling system remains **the canonical, comprehensive toolkit** for processing and understanding visually-rich documents in multiple languages.

# Scope & Objectives

**In-Scope PaperMage Features:** The reimplementation will cover every major feature of PaperMage’s pipeline as documented in its repository and publication. Key features to retain or improve (with references to PaperMage’s original implementation files) include:

- **Multilayer Document Representation:** PaperMage’s `Document` class (in **papermage/magelib** module) organizes content into layers such as symbols (full text), tokens, words, lines (rows), sentences, sections, figures, tables, etc., each stored as an `Entity` with text *spans* and coordinate *boxes* ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=PaperMage%27s%20%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D1%83%D0%B5%D1%82%20%D0%B4%D0%B2%D0%B5%20%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5,%D0%B4%D0%B0%D0%B6%D0%B5%20%D0%BD%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%80%D0%B0%D0%B7%D0%BB%D0%B8%D1%87%D0%B8%D1%8F%20%D0%B2%20%D0%BC%D0%B0%D0%BA%D0%B5%D1%82%D0%B5)) ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,words%27%2C%20%27sentences%27%2C%20%27blocks%27%2C%20%27vila_entities%27%2C%20%27titles)). This design allows cross-referencing between layers (e.g. a Sentence can retrieve its Tokens or the Page it lies on). *Docling equivalent:* The `DoclingDocument` model in **docling-core** provides a unified schema for text and layout, categorizing content into text items, tables, pictures, etc., with a tree structure for document hierarchy ([Docling Document - Docling](https://docling-project.github.io/docling/concepts/docling_document/#:~:text=A%20%60DoclingDocument%60%20exposes%20top,are%20stored%20in%20these%20fields)). We will map Docling’s content items to PaperMage’s layers (e.g. Docling text items for paragraphs/headings will populate PaperMage’s sentences/sections layers, Docling pictures -> figures, etc.), preserving the span-and-box indexing approach. **Objective:** Ensure the new `Document` (or JSON output) contains all layers and cross-links that PaperMage provided, using Docling’s data structures under the hood.

Maintain Output Compatibility: Preserve the existing PaperMage JSON output format and Document API externally. The JSON should remain of the form {"symbols": "<full text>", "entities": {...}, "metadata": {...}} with sub-structures like rows, tokens, words, blocks, sentences etc.​
github.com
. Internally use Docling’s DoclingDocument and related data types, converting them to the PaperMage JSON schema via a dedicated converter module. This provides continuity for any downstream consumers expecting PaperMage’s format.
F

- **PDF Parsing (Text & Layout Extraction):** PaperMage uses a PDF parser (based on PDFPlumber) to extract all text from a PDF into the `.symbols` string and initial layout-based entities: pages, rows (lines), blocks, etc., each with bounding boxes ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,MIT%20License%20utility)). The code for this resides in PaperMage’s parser classes (e.g. `PDFPlumberParser` in *papermage* library) and is invoked via `CoreRecipe.from_pdf()` ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=match%20at%20L601%20def%20from_pdf,doc%20%3D%20self.parser.parse%28input_pdf_path%3Dpdf)). *Docling equivalent:* **docling-parse** will perform text extraction, providing character, word, and line-level outputs with coordinates ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=Simple%20package%20to%20extract%20text%2C,extracted%20paths%20and%20bitmap%20resources)). The `DoclingPdfParser` (C++ backend with Python binding) will replace PDFPlumber’s functionality, yielding a `PdfDocument` object with structured text spans and page element info ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=from%20docling_core,pdf_parser%20import%20DoclingPdfParser%2C%20PdfDocument)). We will convert that into our `Document` format (populating `.symbols` and base layers). **Objective:** Achieve at least parity in text and layout extraction – including handling of multi-column layouts and reading order. Docling’s advanced layout analysis (which accounts for reading order and preserves structure) should ensure that what PaperMage called “rows” (text lines in reading order per page) are correctly identified ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=Simple%20package%20to%20extract%20text%2C,extracted%20paths%20and%20bitmap%20resources)). The RTL support introduced in version 3.4.0 enables proper handling of languages like Hebrew and Arabic, with dedicated utilities for RTL text normalization and box alignment. The parsing component must also capture tables, vector graphics, and images from the PDF (areas where Docling's parser provides built-in support that can enhance what PaperMage had)..

- **Image Rasterization:** PaperMage optionally rasterizes each PDF page to an image (using PDF2Image) to enable computer vision tasks ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=MIT%20License%20utility)). This appears in the pipeline via a `Rasterizer` class and is used for tasks like figure extraction. *Docling equivalent:* Docling’s parser can extract embedded bitmaps and also provide page renderings if needed ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=Simple%20package%20to%20extract%20text%2C,extracted%20paths%20and%20bitmap%20resources)). If not directly available, we can integrate a similar approach (using PDFium or Poppler through docling-parse) to obtain page images. These will populate the `images` layer in the output (analogous to PaperMage’s `Document.images`). **Objective:** Retain the ability to get page images for downstream analysis (figures detection, etc.). We will ensure the pipeline includes an image output per page (at least as an option or for tests), taking advantage of docling-parse’s capability to yield bitmap resources with coordinates (e.g. for images embedded in PDF) ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=Simple%20package%20to%20extract%20text%2C,extracted%20paths%20and%20bitmap%20resources)). 

- **Structural Segment Detection (Titles, Sections, etc.):** PaperMage uses **Predictors** (in *papermage/predictors/*, leveraging ML models) to identify high-level document elements. For example, the I-VILA model is used to classify regions into title, abstract, headings, figures, tables, captions, footnotes, etc. ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=%27words%27%2C%20%27sentences%27%2C%20%27blocks%27%2C%20%27vila_entities%27%2C%20%27titles%27%2C,authors%27%2C%20%27abstracts%27%2C%20%27keywords%27%2C%20%27sections%27%2C%20%27lists)) ([[PDF] PaperMage: A Unified Toolkit for Processing, Representing, and ...](https://aclanthology.org/2023.emnlp-demo.45.pdf#:~:text=,a%20similar%20token%20mapping)). The `CoreRecipe` by default loads an *i-vila* predictor (from a HuggingFace path) to produce layers like `titles`, `sections`, `figures`, `captions`, etc. ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=class%20CoreRecipe,layoutlm)). *Docling equivalent:* Docling’s roadmap includes metadata extraction of title, authors, references, etc. ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=Coming%20soon)), and the **docling-ibm-models** package provides pretrained vision-language models (e.g. **SmolDocling** on HuggingFace for layout classification). For this migration, we will implement a `StructurePredictor` module (possibly reusing PaperMage’s I-VILA model weights or a comparable Docling model) to replicate these classifications. **Objective:** All semantic layers that PaperMage produced (sections, list items, references, equations, algorithms, etc.) should be generated. We will integrate a predictor that takes the Docling-parsed content (text blocks, lines) and outputs labels to construct those layers (e.g. group lines into a “section” entity if labeled as Section-heading onward until next section, etc.). Each such predictor might correspond to a specific PaperMage layer group. This ensures no loss of semantic detail – the new pipeline will still identify titles, headings, figure captions, references, etc., either via a ML model or rule-based heuristics as needed. (If certain categories are not covered by available Docling models initially, we will mark them for future integration while possibly using simpler proxies for v1.)

- **Table and Figure Handling:** PaperMage identifies tables and figures as entities with associated captions. For figures, it likely uses a combination of PDF image extraction and predictor classification to label figure regions and their caption text. Tables are detected and recorded (though PaperMage may treat them similarly to figures as a block). *Docling equivalent:* Docling has explicit support for table structure extraction – representing tables as a collection of cells (in `TableItem`) with coordinates ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=,Markdown%2C%20HTML%2C%20and%20lossless%20JSON)). This is an improvement over PaperMage, which did not fully structure table contents. We will use docling’s table parser output to populate the `tables` layer, providing not just a bounding box but also the table’s text content arranged in rows and columns. For figures, Docling’s `pictures` output (images or graphics detected) will help identify figure regions. We will implement logic to match figures with nearby caption text (e.g. using spatial proximity on the page). **Objective:** Maintain the **Figures** and **Tables** layers in output. For tables, enrich the output by preserving the internal structure if possible (this can be marked as an improvement over PaperMage’s simpler table bounding box). For figures, ensure that extracted images are included (either as image files or as references in JSON) and that captions are linked. This fulfills the PaperMage use-case of being able to extract all visuals and their descriptions from a paper.

- **Entities and References:** PaperMage’s `entities` layer in JSON serves as a catch-all for all extracted segments, and `relations` is used to store links between entities (e.g. citation markers to reference entries). While PaperMage provided the framework, implementing actual citation linking might have been left to the user. *Docling equivalent:* We will continue to output an `entities` dictionary in JSON containing all entity lists (this is how PaperMage serializes the Document ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=%7B%20,%5B...%5D))). For **relations** (e.g. linking a citation mention to a bibliography entry), if time permits, we will implement a simple matching (e.g. detect reference citations in text like “[12]” and link to the item #12 in the bibliography layer). Docling does not yet automate citation linking, so this may be done with a lightweight approach or deferred to future work. **Objective:** Include at least the placeholders for `entities` and `relations` in the JSON so that we **retain full compatibility with PaperMage’s output schema**. Where possible, populate relations (like figure-caption pairing or citation-reference mapping) using docling data or straightforward heuristics, matching or exceeding PaperMage’s capabilities.

- **Persistence (Serialization):** PaperMage supports saving a parsed Document to JSON and loading it back (`Document.to_json()` and `Document.from_json()`) ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=import%20json%20with%20open%28%27filename,to_json%28%29%2C%20f_out%2C%20indent%3D4)) ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=These%20can%20be%20used%20to,again%20via)). This is critical for pipeline workflows (e.g., parse once, then apply more predictors later). *Docling equivalent:* Docling’s `DoclingDocument` is a Pydantic model that can easily be serialized to JSON (with a defined schema) ([GitHub - docling-project/docling-core: A python library to define and validate data types in Docling.](https://github.com/DS4SD/docling-core#:~:text=,using%20the%20pydantic%20class%20definition)). We will implement `to_json()` on our new Document object by converting the internal DoclingDocument to a PaperMage-style dict. Likewise, a `from_json()` that creates our Document (or directly a DoclingDocument) from a saved JSON will be provided. **Objective:** The JSON output **format will exactly match PaperMage v0.18+** (so that existing consumers of PaperMage JSON need not change). Internally, we ensure that this JSON also conforms to Docling’s schema (which is flexible enough to cover all needed fields). We will validate this by round-tripping: `doc = parser_docling.parse(pdf); json = doc.to_json(); doc2 = Document.from_json(json)` – `doc2` should be equivalent to `doc`. Additionally, we leverage Docling’s JSON schema validation via docling-core to ensure our output is not malformed.

**Out of Scope / Future Work:** The core scope is a like-for-like reimplementation. We note that some advanced PaperMage predictors (e.g., full NLP entity extraction on content text, or user-interactive visualizations) are beyond current scope. Also, while we support RTL text, comprehensive support for mixed-direction text layouts (mixed LTR/RTL on the same line) and OCR for scanned PDFs are considered future enhancements. Integrations with generative AI (which Docling facilitates) or the Semantic Scholar Dolma project are not in scope for this PRD, but the design will not preclude adding those later.

**RTL Support Objective:** In addition to feature parity, **an explicit objective is correct handling of Hebrew and other RTL texts**, which PaperMage did not guarantee. This includes preserving the natural reading order of tokens in `.symbols` and other layers for RTL segments, adjusting span indices and bounding box associations as needed. The output JSON should represent Hebrew text in the correct order a human would read it (right-to-left), and all coordinate-based alignments (e.g. the first token in a Hebrew sentence has the right-most box) must remain consistent. The scope covers implementing necessary text reordering at the parser or post-processing level to achieve this. We consider this a critical improvement to make PaperMage-Docling truly multilingual.

**Docling-to-PaperMage JSON Conversion Module:** A critical piece for compatibility is translating the DoclingDocument output into the exact JSON structure that PaperMage previously produced. We will implement a dedicated module, e.g. api/json_converter.py, responsible for this transformation. When Docling returns a DoclingDocument (or its JSON), the converter will construct a Python dictionary matching Document.to_json() format of PaperMage. This includes: assembling the full text content for the symbols field (Docling’s DoclingDocument likely already has a way to get the full text in reading order – we will utilize that), and populating the entities sub-dictionary with lists for each entity type (tokens, words, sentences, blocks, rows, etc.). For each entity, we need to extract the relevant attributes from Docling. For example:
Tokens/Words: Docling-Parse provides word and character bounding boxes. We will iterate over Docling’s word-level text units (e.g., pred_page.iterate_cells(unit_type=TextCellUnit.WORD) as shown in Docling’s docs​
github.com
) to collect each word’s text and coordinates, formatting them as PaperMage word entities. If PaperMage distinguishes tokens vs words (as indicated by both lists in the JSON), we will map Docling’s output appropriately (possibly treating punctuation or smaller units as tokens, or simply duplicating words as tokens if needed to maintain the same layers). This detail will be clarified by reviewing PaperMage’s original Document.to_json() implementation and matching it with Docling’s concepts.
Blocks/Sections: Docling performs layout analysis, identifying text blocks (paragraphs, columns, section headers, etc.). It likely labels them or groups lines into higher-level segments. We will use Docling’s layout grouping to fill the blocks list. Each block entity in PaperMage JSON can contain attributes like bounding box and span of text indices in symbols. DoclingDocument might allow us to traverse sections or regions of the page layout – we’ll convert those into our block representation.
Rows (Table Rows or Lines): If the original PaperMage uses rows to represent table rows or text lines, we will derive those from Docling. Docling explicitly supports table structure extraction​
github.com
. We will identify table segments in DoclingDocument (perhaps it has a notion of table objects with cells and rows) and output them as a list of rows entities, each containing the text or cell contents of that row and positional info. If instead rows meant text line rows, Docling’s line-level extraction can be used. In either case, Docling’s rich structure should allow extracting these without custom heuristics.
Figures and Tables: Although the base JSON example​
github.com
 didn’t list figures or tables, PaperMage could add those via predictors (BoxPredictor) as additional layers. We will ensure parity by including figure and table entities if they are part of PaperMage’s scope. Docling already extracts images (bitmap figures) with coordinates​
github.com
 and can classify them, and detect tables. So, if the CoreRecipe in PaperMage originally added figure/table annotations, our Docling pipeline will natively provide those. The converter will create figures and tables lists in the output JSON (if expected by consumers), containing analogous info (e.g., figure bounding boxes, possibly references to extracted images or captions if applicable). If PaperMage’s JSON didn’t include the actual image bytes (it likely did not, to keep JSON lightweight), we will not include them either – instead, we might provide figure references in JSON with coordinates and let the client fetch images separately if needed. Docling’s responsibility in extracting figure content means we don’t need a separate rasterizer to generate figure images; if such raster images are needed for any reason, Docling can render page regions via its render_as_image functionality.
Metadata: We will populate the metadata field of the JSON using Docling’s metadata if available. This might include the number of pages, document title, etc., as originally included by PaperMage. Docling might provide some metadata (like PDF info, language, etc.). We ensure all original metadata fields are present so that Document.from_json() can reconstruct the document if needed.
The json_converter.py will serve as the single translation layer between Docling’s internal representation and PaperMage’s external format. By isolating this logic, we make it easy to adjust if needed and ensure that elsewhere in the code we can work with Docling types freely. This also means externally, if someone uses PaperMage as a library, doc.to_json() will effectively be using this converter under the hood, and Document.from_json() might create a DoclingDocument or a thin wrapper from the stored data. Maintaining this backward compatibility layer is critical to not breaking existing workflows.

# Functional & Non-Functional Requirements

## Functional Requirements

The system shall fulfill each functional aspect of PaperMage by utilizing Docling components or custom code. The mapping below pairs each PaperMage feature (and the file or class that implemented it) with its Docling-based replacement:

- **PDF Text Extraction & Layout:** *Requirement:* Ingest a PDF and extract all text with layout positions into a Document object. In PaperMage this is done by `PDFPlumberParser.parse()` (MIT-licensed pdfplumber backend) – see call in `CoreRecipe.from_pdf` ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=match%20at%20L601%20def%20from_pdf,doc%20%3D%20self.parser.parse%28input_pdf_path%3Dpdf)). **Implementation:** Use `DoclingPdfParser` from **docling-parse** to load the PDF and produce a low-level `PdfDocument` structure ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=from%20docling_core,pdf_parser%20import%20DoclingPdfParser%2C%20PdfDocument)). Convert this into our Document’s `.symbols` string and base entity layers. All characters in the PDF must appear in `.symbols` in reading order. All lines of text must be segmented as `rows` with their coordinates. We will verify that docling’s **line output** corresponds to logical reading order per page (Docling’s parser is designed to output char, word, line level info ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=Simple%20package%20to%20extract%20text%2C,extracted%20paths%20and%20bitmap%20resources)), which we will trust for initial ordering, adjusting for RTL as needed). *Acceptance criteria:* Given a test PDF, the sequence of text in `.symbols` and the count of pages, lines, and tokens match those from running PaperMage on the same PDF.

- **Coordinate Precision:** *Requirement:* Preserve the positional information (bounding boxes) for each text segment (tokens, lines, etc.). In PaperMage, `Span` and `Box` classes (in *papermage/magelib/box.py* and *span.py*) are used to record character index ranges and their coordinates ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=Each%20,about%20its%20contents%20and%20position)). **Implementation:** For each Docling text item (line or word), retrieve its bounding box (Docling uses PDF coordinates natively). Construct `Box` objects for each span in our Document. Ensure that when an Entity (e.g. a Section heading) spans multiple discontinuous areas (like a heading with a line break or a sentence across page break), multiple spans and boxes are stored just like PaperMage did ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=PaperMage%27s%20%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D1%83%D0%B5%D1%82%20%D0%B4%D0%B2%D0%B5%20%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5,%D0%B4%D0%B0%D0%B6%D0%B5%20%D0%BD%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%80%D0%B0%D0%B7%D0%BB%D0%B8%D1%87%D0%B8%D1%8F%20%D0%B2%20%D0%BC%D0%B0%D0%BA%D0%B5%D1%82%D0%B5)). *Acceptance criteria:* Output JSON for any text entity includes a list of `boxes` matching the PDF coordinates (we will check a few known values against PaperMage’s output to ensure consistency).

- **Page Segmentation:** *Requirement:* Identify page boundaries and number pages in the Document. PaperMage represents pages as an entity layer (`doc.pages` iterable) where each Page entity has a span covering the characters on that page. **Implementation:** Docling’s parser inherently processes page by page; we will insert a Page entity break whenever the page number increases. This means constructing `Page` entities with spans covering the index range in `.symbols` for that page’s text, and a `metadata` field for page number. We will use the page info from Docling (likely each text item carries a page index). *Acceptance criteria:* The Document’s `pages` list length equals the PDF page count, and each Page’s span covers exactly its page’s text. The first character index of page *N* entity should align with the first char of that page’s content in `.symbols`.

- **Tokenization and Words:** *Requirement:* Provide token-level segmentation of text (where tokens are typically words or punctuation units) as well as word-level if distinct. PaperMage outputs both `words` and `tokens` layers ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,words%27%2C%20%27sentences%27%2C%20%27blocks%27%2C%20%27vila_entities%27%2C%20%27titles)). **Implementation:** Docling-parse can output text at **word level** (it groups characters into words). We will likely treat Docling “word” outputs as PaperMage `words`. For `tokens`, we may adopt the same as words or further split if needed (e.g., splitting punctuation from words, depending on how PaperMage defines them). To confirm: PaperMage likely defines `tokens` as smaller units than `words` (perhaps including punctuation separately). We will replicate its logic (referencing PaperMage’s tokenization code in *papermage/magelib/tokenizer* if available). If such code is not explicit, we assume `tokens` ≈ `words` for initial implementation, ensuring that layer exists for compatibility. *Acceptance criteria:* Each `word` in output corresponds to a space-separated segment in the original PDF text, and the `tokens` layer is present (even if identical to words). This can be validated against a known output from PaperMage (ensuring same count of tokens).

- **Higher-level Segments (Sentences, Paragraphs, Sections):** *Requirement:* Identify sentences and sections from the text. PaperMage’s default predictors include a sentence splitter (likely using a punctuation heuristic or model) and the structural segmentation model (I-VILA) that yields sections and other block labels. **Implementation:** We will implement a **SentenceSegmenter** (could use a simple rule-based splitter on `.symbols` or leverage an NLP library since scientific text is well-formed). For sections and other headings, we plan a **LayoutClassifier** predictor. Initially, we propose using the I-VILA model via HuggingFace (AllenAI’s `ivila-row-layoutlm` checkpoint) to classify each text block (line or group of lines) into categories as PaperMage did ([[PDF] PaperMage: A Unified Toolkit for Processing, Representing, and ...](https://aclanthology.org/2023.emnlp-demo.45.pdf#:~:text=,a%20similar%20token%20mapping)). This can be done by feeding the Docling-parsed page content into the model (since I-VILA expects text+layout features). If docling-ibm-models provides an alternative (e.g., a lightweight layout classifier), we may use that for efficiency. *Acceptance criteria:* The output JSON should have a `sentences` layer splitting the text correctly (e.g., the number of sentences in the abstract matches manual count), and a `sections` layer that lists sections with titles matching those visually present in the PDF (e.g., “Introduction”, “Methods”, etc., each as an entity). In addition, layers like `title`, `authors`, `abstract` should appear if applicable, containing the content identified as such. These can be compared to PaperMage’s output on a sample scholarly article – they should match in content and count (acknowledging minor model differences if any, but overall structure should align).

- **Tables and Lists:** *Requirement:* Identify list items and list structures, as well as tables with their contents. PaperMage had a `lists` layer for enumerated or bulleted lists and a `tables` layer for tables (likely capturing their position). **Implementation:** Docling’s output includes detection of list containers and list items (represented as `Group` nodes of type list in the `groups` field ([Docling Document - Docling](https://docling-project.github.io/docling/concepts/docling_document/#:~:text=,a%20list%2C%20a%20chapter)) ([Docling Document - Docling](https://docling-project.github.io/docling/concepts/docling_document/#:~:text=Grouping))). We will traverse Docling’s content tree to find list structures and translate them into a flat `lists` layer similar to PaperMage (each list entity could correspond to a group of list item text spans). For tables, as noted, docling provides structured tables. We will output each table as an entity with potentially a nested structure or at least a reference to the cell contents. If PaperMage’s original output only provided tables as one entity per table (with no internal structure), we might do the same for compatibility, but store the detailed structure in `metadata` or keep it for future extension. *Acceptance criteria:* Lists and sublists in a document (for instance, an itemized conclusion list in a PDF) are captured as separate list item entities in the output. Tables present in a PDF (e.g., a results table) appear in the JSON `tables` list with correct spans (covering the text of the table). If we compare to PaperMage’s JSON, the number of list items and tables and their text content should align.

- **Figures, Captions, and Images:** *Requirement:* Extract figure images and their captions. In PaperMage, `figures` and `captions` are layers – figures likely containing the figure label or content region, and captions containing the descriptive text. **Implementation:** We will use docling to extract images: docling-parse should retrieve any embedded images or vector drawing objects as `pictures`. For each detected picture or graphic, create a `Figure` entity (with a Box spanning that region on the page). Then, attempt to find a caption: often captions immediately follow the figure on the page. We can take the text block below each figure’s position and mark it as a `caption` entity (and link it via a relation to the figure). If the layout classifier model identifies captions (I-VILA has a class for caption), we will directly use that label to populate the `captions` layer. *Acceptance criteria:* Every figure in the PDF (by visual inspection) is represented in the output. The `figures` list count matches PaperMage’s output for a sample (e.g., if a paper has 3 figures, we output 3 figure entities and their corresponding caption entities). Captions text in JSON should exactly match the text under the figures in the PDF. The image data itself might not be embedded in JSON (to keep it text-only), but we will store perhaps a path or an ID reference if images are saved separately (the specific approach can mirror PaperMage’s handling of images – likely PaperMage did not embed raw image bytes in JSON but provided coordinates and maybe allowed separate extraction).

- **Bibliography and Citations:** *Requirement:* Identify the bibliography section and individual reference entries, as well as citation markers in the text. PaperMage’s predictors included `bibliographies` (the reference section as a whole) and presumably each reference entry as an `Entity`. It also could capture `footnotes` and perhaps equation references. **Implementation:** We will detect the start of the references section by looking for common headers like “References” or by the layout classifier’s output (if I-VILA classifies blocks as bibliography). Once identified, every line or paragraph until end-of-document can be grouped into individual reference entities (likely separated by line breaks or numbering). These will form the `bibliographies` layer (a list of reference entry entities). Citation markers in body text (e.g., “[12]” or “Doe et al., 2020”) might be detected via regex. We can populate a `cite_marks` layer (if desired, or include them as a type of inline entity in `entities`). For linking, as mentioned, we might populate the `relations` field: each citation mark could have a relation referencing the corresponding bibliography entry entity (by index or id). *Acceptance criteria:* The output should list reference entries (for example, if a paper has 10 references, we output 10 bibliography entities with their text content). If PaperMage’s JSON did so, we should match their formatting (likely the entire reference string as one entity span). Citation markers in the text, if we choose to output them, should correspond to those references. This can be tested on a known PDF with citations – verifying that our bibliography entries match those that PaperMage would produce (if we have their output or by manual checking).

- **Output JSON Schema Compliance:** *Requirement:* The JSON output must include all the same keys/structure as PaperMage’s (for full compatibility), and also be a valid DoclingDocument (if possible). **Implementation:** Each layer of entities will be a key in the `"entities"` dictionary in JSON, as PaperMage does ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=%7B%20,%5B...%5D)). We will include `"symbols"` (the full text) and `"metadata"` at top level, same as PaperMage. We will run `DoclingDocument.model_validate(json)` from docling-core as a sanity check to ensure our JSON doesn’t violate Docling’s schema ([GitHub - docling-project/docling-core: A python library to define and validate data types in Docling.](https://github.com/DS4SD/docling-core#:~:text=,using%20the%20pydantic%20class%20definition)). Differences (if any) will be noted: e.g., Docling expects `texts`, `tables`, etc. at top level instead of our layered approach. Our primary commitment is to PaperMage’s format, so if conflicts arise, we favor PaperMage format but keep as much alignment with Docling’s schema as possible. *Acceptance criteria:* A set of sample outputs passes a JSON schema validation for PaperMage’s documented format (if available), and our own tests confirm that the keys and nesting match exactly what PaperMage produces for the same input. No required field from PaperMage is missing. (Docling’s schema validation will be secondary – any non-conformance will be evaluated if it’s easy to fix without breaking compatibility.)

In addition to the above specific features, the following general functional requirements apply:

- **Library API Parity:** The new implementation should expose a similar API for developers. For example, users should be able to do `from papermage_docling import CoreRecipe; doc = CoreRecipe().run("file.pdf")` analogous to the original ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,first%20time%20from%20a%20PDF)). We will either mimic the `CoreRecipe` class or provide an equivalent function. The returned `doc` should behave like a PaperMage `Document` object (at least exposing attributes like `.symbols`, `.layers`, and iterables like `.pages`, `.tokens`, etc.). This may be achieved by wrapping the DoclingDocument in a lightweight compatibility class.

- **Batch Processing Capability:** Docling is built to handle batch and large documents (docling-serve can queue jobs). Our core library will focus on single-document processing (like PaperMage). However, we ensure that it can be called in parallel (no global state) and could be integrated in a multiprocessing or asynchronous context. The FastAPI service (described later) will allow multiple requests concurrently, leveraging docling’s thread-safe design.

- **Extensibility:** The design should allow adding new predictors easily, akin to PaperMage’s plugin system for predictors. For instance, one could drop in a new `Predictor` class in the `predictors/` directory, and the pipeline can pick it up (perhaps via a config or by explicitly coding it in CoreRecipe). This is more of a design principle we will maintain – not a user-facing requirement, but ensures the architecture is modular.

## Non-Functional Requirements

- **Performance:** The PaperMage-Docling system should perform at least as well as PaperMage on equivalent hardware, and ideally better. Docling’s parser is implemented in C++ for speed and is optimized for large documents ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=Simple%20package%20to%20extract%20text%2C,extracted%20paths%20and%20bitmap%20resources)). We expect significantly faster parsing of PDFs compared to PDFPlumber (especially for long papers or books). Our additional Python overhead for predictors should not bottleneck the process. *Goal:* Parsing and structuring a 10-page scientific paper (with moderate figures and tables) in under **2 seconds** on a typical server CPU. This will be tested against the original PaperMage (which we expect to be slower on pure Python parsing). We will also monitor memory usage – Docling’s extraction should be memory-efficient (streaming if possible). Non-functional acceptance: processing 100 documents in a batch (via the API) does not crash and completes within a reasonable time, demonstrating scalability.

- **Accuracy and Parity:** Non-functional but critical: the output must not just structurally match but also be **accurate**. That is, no loss of text or mis-ordering. The migration should not introduce regression in terms of correctly capturing content. If any differences from PaperMage output occur (due to different PDF parsing algorithms or model predictions), they should be documented and justified (e.g., Docling might extract a header artifact that PaperMage skipped – that could be acceptable if it’s minor). Our testing will measure parity (discussed in Testing section). Essentially, quality of extraction must meet or exceed PaperMage’s known quality (which was high for its domain). 

- **Compatibility and Replaceability:** The solution must be a drop-in replacement for any pipeline currently using PaperMage JSON output or similar API. For instance, if a user’s code expects fields like `doc.pages` or a JSON key `abstracts`, those must exist with the same meanings. We will maintain the same key naming (even if Docling uses different terminology internally). Additionally, the packaging of the library should allow installation via pip (`papermage_docling` or similar) without conflicts, and ideally the same import name `papermage` could be used if we want to masquerade it (though likely we’ll use a new name to avoid confusion). This requirement ensures minimal friction for users upgrading to the new system.

- **Docling-serve Integration:** Ensure that our implementation can integrate with **docling-serve** for deployment. Docling-serve is a FastAPI-based server for Docling that can distribute large jobs across workers ([Docling Project · GitHub](https://github.com/docling-project#:~:text=If%20it%20has%20to%20do,API%20and%20distribute%20large%20jobs)). Our `api_service.py` will be similar (possibly simpler). Non-functionally, we want to be able to run our service in a Docker container (see Deployment) and handle multiple requests. If needed, we will align with docling-serve’s API routes (for example, docling-serve might have a route `/convert` where you POST a document and get JSON). We can follow that convention so that clients/tools built for Docling can use our service interchangeably. Another aspect is **job management**: docling-serve supports asynchronous job submission for large volumes. For our scope, we likely handle requests synchronously (given the relatively fast processing time), but the design will not preclude scaling up to an async job queue if needed.

- **Containerization & DevOps:** The project will include a **Dockerfile** to encapsulate all dependencies (Python, Docling libraries, any system libs like Poppler or Tesseract if needed for images/OCR). The container should be lightweight and based on a standard base (e.g. python:3.11-slim). We consider using the official Docling Docker image as a base if available ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=CONTRIBUTING)), since it would already have docling-core, parse installed. The container must run the API service on a configurable port. For CI, we will use GitHub Actions (a workflow similar to PaperMage’s `.github/workflows` ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=272%20Commits))) to run tests on each commit/pull request, ensuring stability. We will also possibly set up automatic builds to Docker Hub or GitHub Container Registry for ease of deployment.

- **Multilingual & RTL Support:** Beyond Hebrew, the system should be robust for other languages, including those using non-Latin scripts or RTL scripts (Arabic, Persian). This means not hard-coding anything specific to Hebrew but implementing a general solution for bi-directional text. Non-functionally, we require use of Unicode throughout (which we do) and possibly integration of the Python bidi algorithm or ICU if needed for full correctness. Another aspect is fonts/encodings: Docling parse presumably handles Unicode text extraction; we must ensure that if a PDF has Hebrew characters, they appear correctly (not as gibberish). We may need to specify the proper locale or font mapping in docling if required. In tests, we will include some documents in languages like Chinese (to test multi-byte and non-Latin) and ensure those work. The performance in those cases should remain good (with possible OCR needed if PDFs are scanned, but that’s outside pure parsing scope). 

- **Maintainability & Modularity:** The use of Docling already improves maintainability (active open-source project backed by IBM). Our code will be clearly modularized (parsing vs prediction vs serving), making it easier to update or replace parts. For example, if a better layout model comes out, one can swap out `structure_predictor.py` without touching parsing. We will write clean code with documentation comments especially where we convert between Docling and PaperMage formats. This is a requirement to facilitate future developers (or future us) to extend the tool, e.g., when Docling releases new features (like chart detection), we might integrate those.

- **Security:** As a backend service that will parse potentially untrusted PDFs, we should consider security. PDF parsing can be a vector for DoS or worse if not careful (e.g., malicious PDFs with huge content). Docling-parse being in C++ means we rely on their safety (we should track their updates for any security fixes). Our service should enforce reasonable file size/page count limits to avoid extreme cases (for instance, we may set a limit of, say, 500 pages per document by default or require a special flag to override, to avoid timeouts). Also, dependencies should be up to date to avoid known vulnerabilities.

By meeting all the above requirements, the new implementation will serve as a **faithful and improved reincarnation** of PaperMage. It ensures functional equivalence on all key tasks and introduces enhancements in speed, scalability, and multilingual handling.

# System Architecture & Directory Layout

The PaperMage reimplementation will be structured as a Python package with a clear separation of concerns: parsing, prediction, and serving. Below is the **project directory layout** (files and folders) finalized for our implementation:

```
papermage_docling/
├── parsers/
│   ├── __init__.py                      # Need to create/rename
│   ├── docling_pdf_parser.py            # Need to create/rename from parser_docling.py
│   └── docling_ocr_parser.py            # Need to create
├── predictors/
│   ├── __init__.py                      # Already exists
│   ├── structure_predictor.py           # Already exists
│   ├── table_predictor.py               # Already exists
│   ├── language_predictor.py            # Already exists, not in PRD
│   └── rtl_utils.py                     # Already exists, not in PRD
├── rasterizers/                         # Misspelled as "rastisizers"
│   ├── __init__.py                      # Need to create
│   └── pdf_rasterizer.py                # Need to create
├── visualizers/
│   ├── __init__.py                      # Need to create
│   └── docling_visual.py                # Need to create
├── api/
├── converters/
├── └── docling_to_papermage_converter.py    
├── tests/
│   ├── test_parsers/                    # Need to create subdirectory 
│   │   ├── test_docling_pdf_parser.py   # Need to create
│   │   └── test_docling_ocr_parser.py   # Need to create
│   ├── test_predictors/                 # Need to create subdirectory
│   │   └── test_structure_predictor.py  # Need to create
│   ├── test_visual_tests/               # Need to create subdirectory
│   │   └── test_raster_and_overlay.py   # Need to create
│   ├── test_api.py                      # Already exists
│   ├── test_end_to_end.py               # Already exists
│   ├── test_parser.py                   # Exists but not in PRD structure
│   └── test_predictors.py               # Exists but not in PRD structure
├── api_service.py                       # Already exists at root
├── Dockerfile                           # Already exists at root
├── README.md                            # Already exists at root
├── prd.md                               # Exists but not in PRD structure
└── pyproject.toml                       # Already exists at root
```

**Core Components:**

- **`parser_docling.py`:** This module contains the `DoclingParser` class (or equivalent function) which orchestrates PDF parsing using Docling. It wraps the docling-parse functionality. For example, `DoclingParser.parse(pdf_path)` will internally create a `DoclingPdfParser` instance ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=from%20docling_core,pdf_parser%20import%20DoclingPdfParser%2C%20PdfDocument)), parse the PDF into a `PdfDocument`, then convert that into our high-level Document (with PaperMage-compatible layers). This file corresponds conceptually to PaperMage’s parser wrappers (e.g., `pdfplumber_parser.py` in the original - https://github.com/allenai/papermage/blob/main/papermage/parsers/pdfplumber_parser.py). It will also import docling-core types for constructing the output objects. We cite parallels in docling-serve: in the docling-serve code, after file upload it likely calls docling to parse; our `parser_docling.py` plays a similar role but returns the result to the caller (in memory). 

- **`predictors/`:** This package replicates PaperMage’s predictor plugin system - https://github.com/allenai/papermage/tree/main/papermage/predictors. Each predictor module will house logic to add a certain layer or annotation to the Document. For example:
  - `structure_predictor.py` may define a `StructurePredictor` class with a method `apply(document)` that uses an ML model or rules to identify titles, headings, sections, etc., and populates those layers (by creating new Entity objects for each and attaching them to the Document). This is analogous to PaperMage’s integration of the I-VILA model (which was likely in a predictor class in *papermage/predictors/vila.py*). It will use either an imported HuggingFace model or possibly a call to docling’s model API if available.
  - `table_predictor.py` could refine or validate table structures. Docling might already output tables; this predictor might ensure that if Docling didn’t segment a table that spans multiple pages, we handle it, or simply mark all table text as one entity in our layers.
  - `language_predictor.py` could use docling’s upcoming language detection (once implemented) or a library like `langdetect` to set a metadata field in Document for language. This is optional, but we include it to demonstrate how additional predictors can be plugged (e.g., one might want to detect if a document is mostly Hebrew vs English, to decide RTL processing – though in our case we can detect script at parse time too).
  - **`rtl_utils.py`:** This is a utility module rather than a predictor; it provides functions to reorder text and adjust spans for RTL scripts. For instance, `reorder_line(text:str, boxes:list)` might apply the Unicode Bidirectional Algorithm to `text` and reorder the list of `Box` coordinates to match the visual order. It might also normalize Hebrew characters (some PDFs may decompose letters). This module encapsulates the logic needed to support RTL in the parsing stage. We separate it for clarity and potential reuse.

  The predictors modules will be used by the `parser_docling.py` pipeline after basic parsing. In PaperMage, the `CoreRecipe.run()` calls parser, then rasterizer, then runs each predictor ([PaperMage: A Novel PDF Parsing Framework - AI Exploration Journey](https://aiexpjourney.substack.com/p/papermage-a-novel-pdf-parsing-framework#:~:text=PaperMage%3A%20A%20Novel%20PDF%20Parsing,images%20%3D%20self.rasterizer.rasterize%28input_pdf_path%3Dpdf)). We will follow that sequence: e.g., in `DoclingParser.parse()`, after obtaining the Document with base layers, call `StructurePredictor.apply(doc)`, `TablePredictor.apply(doc)`, etc. This design allows easy extension or toggling of predictors (just like recipes in PaperMage could be customized).

- **`api_service.py`:** This file sets up the FastAPI application for serving the parser as a web service. It will likely create a FastAPI `app`, define an endpoint (e.g., `POST /parse_pdf`) which accepts a PDF file upload and returns the JSON output. Implementation-wise, it will instantiate the `DoclingParser` and maybe keep it around (though stateless is fine since DoclingParser has no heavy state). It will also handle CORS (if needed), and use Uvicorn server if run directly. This is influenced by docling-serve’s approach – docling-serve probably has similar route definitions (we saw mention of “display version in fastapi docs” ([docling-project/docling-serve v0.5.0 on GitHub - NewReleases.io](https://newreleases.io/project/github/docling-project/docling-serve/release/v0.5.0#:~:text=NewReleases,ed851c9%20%29)), implying they have an auto docs with version, which we can emulate by adding a `/version` route or including `papermage_docling` version in OpenAPI description). If needed, this service could also include a simple **Gradio** interface for demonstration: since Gradio can be launched from within a Python script, we might include a conditional section to launch Gradio UI (for example, if run as `__main__`, start a Gradio app that lets a user upload a PDF and view JSON or some summary).

- **`tests/`:** The test suite is organized to mirror functionality. Key test files:
  - `test_parser.py`: Unit tests for parsing. For example, feed a simple PDF (we can use the one from PaperMage’s tests, e.g. `tests/fixtures/papermage.pdf` from the original ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=recipe%20%3D%20CoreRecipe,tests%2Ffixtures%2Fpapermage.pdf))) and assert that the Document’s basic layers (symbols, pages, tokens) are correctly populated. Also test edge cases like an empty PDF or a PDF with images only.
  - `test_predictors.py`: Test individual predictor outputs. For instance, take a known text (maybe use a small snippet as Document) and run `StructurePredictor` to see if it identifies a title we expect. Or test `rtl_utils.reorder_line` with sample Hebrew string to ensure it reverses correctly.
  - `test_end_to_end.py`: High-level tests that run the entire pipeline on sample inputs and compare the output JSON to a reference (the reference could be obtained by running original PaperMage on that input and storing the JSON). We will include the primary use-case test: parse a full scientific paper PDF and diff the JSON against PaperMage’s (differences should be minimal, e.g., perhaps numeric differences in coordinates by small epsilon or slight differences in model labeling if any).
  - `test_api.py`: If our API service is included, use FastAPI’s TestClient to simulate uploading a file and verify the response format and content.

  The tests ensure we meet both functional and some performance criteria. They will be run in CI to guard against regressions.

- **`Dockerfile`:** Defines how to build a container for the service. Likely starts from `python:3.11-slim`, installs system packages (maybe `poppler-utils` if needed for PDF image conversion, although docling-parse likely bundles PDFium so maybe none needed). It then installs our package (which will pull in docling, docling-core, etc. via pip). It will set up to run `uvicorn papermage_docling.api_service:app --host 0.0.0.0 --port 8000` as the entrypoint. We will ensure that this is similar to docling-serve’s container (docling-serve might use gunicorn/uvicorn too). Users can thus deploy this container to serve the parsing API.

- **Configuration & Logging:** Not shown as separate files, but we will use Python’s logging to log events (parsing started, predictors applied, etc., similar to PaperMage’s log lines ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=def%20from_pdf%28self%2C%20pdf%3A%20Path%29%20,doc%20%3D%20self.parser.parse%28input_pdf_path%3Dpdf))). If needed, we might have a config (maybe via environment or a small config file) to toggle things like whether to run heavy predictors or skip images, etc. Initially, defaults will be tuned for full feature extraction.

- **Parallel with docling-serve structure:** The *docling-serve* repository organizes code under a package `docling_serve`. It likely has modules for routes and background tasks. In our simpler case, `api_service.py` encompasses the creation of routes. We will keep it straightforward (one file) unless it grows, in which case we might split routes into an `api/` folder. Given scale, one file is fine. The similarity lies in usage of FastAPI and Uvicorn, and potentially using Pydantic models for request/response (docling-serve might define request schemas; we can just accept `UploadFile` and return raw JSON). We will cite docling-serve’s approach to job queuing: it might use **Celery** or Python threads for async conversion. If large jobs need to be handled, we could integrate **Starlette BackgroundTasks** or Celery in future. For now, the architecture handles requests synchronously within FastAPI workers.

Overall, the architecture is designed such that **Docling does the heavy lifting of PDF conversion and data typing**, and our code layers on the specific logic to mirror PaperMage’s outputs and add RTL support. The diagram below illustrates the flow:

**Processing Flow:**
1. **Input:** PDF file (path or bytes) -> 
2. **Parser (DoclingParser):** calls Docling to extract base content -> intermediate Docling structures (char, word, line, images) -> converts to PaperMage-style Document (symbols + base entities).
3. **Predictors:** sequentially enrich the Document: e.g. StructurePredictor labels blocks as Title/Section -> new entities added; TablePredictor structures tables -> table entities added; etc.
4. **Output:** Final Document (in memory) which can be used in code or serialized to JSON. If via API, JSON is returned to client.
5. **RTL adjustment** is applied during step 2 (after extraction, before creating spans) to ensure any Hebrew/Arabic text segments are stored in correct order.

This modular architecture (Parser -> Predictors -> Output) is analogous to PaperMage’s **Recipe** pipeline ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=,Recipes)), and aligns with Docling’s design where parsing and enrichment are distinct steps ([Docling Document - Docling](https://docling-project.github.io/docling/concepts/docling_document/#:~:text=,FAQ)) ([Docling Document - Docling](https://docling-project.github.io/docling/concepts/docling_document/#:~:text=,Examples)).

By organizing the code in this way, each piece (parsing vs each predictor vs service layer) can be developed and tested in isolation, and replaced or upgraded as needed (for example, if Docling releases a new version with built-in title extraction, we could remove our StructurePredictor and just map their output).

# Implementation Summaries (File-by-File)

Below we provide a technical summary of each major file in the implementation, including key classes/functions, their responsibilities, and references to the original PaperMage source and Docling components they relate to.

- **`parser_docling.py`:** This file implements the core parsing logic. It defines, e.g., a class `DoclingParser` with methods:
  - `parse(input_pdf_path: Union[str, Path]) -> Document`: the main entry point. In pseudocode:
    ```python
    def parse(self, input_pdf_path):
        # 1. Parse PDF using Docling
        pdf_parser = DoclingPdfParser()  # from docling_parse
        pdf_doc: PdfDocument = pdf_parser.load(path_or_stream=str(input_pdf_path)) ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=from%20docling_core,pdf_parser%20import%20DoclingPdfParser%2C%20PdfDocument))
        # 2. Convert to Document
        doc = Document()  # our custom Document class or dict
        doc.symbols = pdf_doc.text  # the full text extracted
        # 3. Build base layers (pages, rows, tokens, etc.) from pdf_doc
        for page_num, page in enumerate(pdf_doc.pages):
            doc.pages.append(Entity(spans=[Span(start_idx, end_idx)], boxes=[...]))
            for line in page.lines:
                # create row entity with span covering that line's text range and box coords
                ...
        for word in pdf_doc.words:
            # create token and/or word entities
            ...
        # 4. Apply RTL fixes
        rtl_utils.normalize_document(doc)
        # 5. Return Document
        return doc
    ```
    This pseudo-flow populates the Document with raw text and layout. It leverages `PdfDocument.pages`, `lines`, `words` etc., which are provided by Docling (the exact API may differ; we will adjust accordingly). The **RTL normalization** step will iterate through text segments (likely line by line) and reorder text and boxes if the text is detected as RTL (using `rtl_utils`). This ensures, for example, that if `pdf_doc.lines[n].text` is "שלום" (which might come out reversed as "םולש" from a naive extractor), we flip it to the correct order.
  - `to_json(doc: Document) -> dict`: (if Document is not a Pydantic model but a custom class or even a dict-like, we can implement a helper here or as a method of Document). It will traverse the Document’s entities and produce the nested JSON structure as per PaperMage. However, if we choose to implement Document as a dataclass or Pydantic model, we might rely on its `.dict()` or so. PaperMage’s `Document.to_json()` essentially collected all entities by layer into lists ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=import%20json%20with%20open%28%27filename,to_json%28%29%2C%20f_out%2C%20indent%3D4)). We will do the same. (This function might also live in the Document class definition if we mimic that).
  - We might also define a `Document` class in this file or another (to represent the output Document with layers as attributes and possibly an internal link to DoclingDocument). For simplicity, we can treat Document as a thin wrapper or even just manipulate the JSON structure directly.
  
  **Origin references:** The logic here replaces PaperMage’s `CoreRecipe.from_pdf` and underlying parser code (e.g., `PDFPlumberParser.parse()`). The chain `self.parser.parse(input_pdf_path=pdf)` in PaperMage ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=def%20from_pdf%28self%2C%20pdf%3A%20Path%29%20,doc%20%3D%20self.parser.parse%28input_pdf_path%3Dpdf)) corresponds to our usage of `DoclingPdfParser.load()` ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=from%20docling_core,pdf_parser%20import%20DoclingPdfParser%2C%20PdfDocument)). The creation of Document layers corresponds to parts of PaperMage’s magelib (e.g., assembling Entities with spans/boxes). For example, the spans and boxes attached to each Entity mirror what PaperMage does as described in its README ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=Each%20,about%20its%20contents%20and%20position)). We will also ensure to log the step “Parsing document...” similar to PaperMage’s log (which we see at  ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=def%20from_pdf%28self%2C%20pdf%3A%20Path%29%20,doc%20%3D%20self.parser.parse%28input_pdf_path%3Dpdf)), they log "Parsing document..." then "Rasterizing..." etc.). After parsing, PaperMage rasterizes images – we will log and call image extraction if needed (Docling might automatically populate `pdf_doc.images`, which we can iterate and save images, linking to Document.images).

  **Docling usage:** uses `DoclingPdfParser` and data classes from `docling_parse` (PdfDocument, possibly TextCellUnit if needed for fine-grained spans ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=from%20docling_core,pdf_parser%20import%20DoclingPdfParser%2C%20PdfDocument))). Also uses `docling_core` for types if we directly construct a DoclingDocument (though likely we'll not create a full DoclingDocument manually, instead just produce our JSON). We cite that docling-parse can produce char-level detail; we might not need char-level beyond assembling words and spans.

- **`predictors/structure_predictor.py`:** Implements the high-level document structure classification. It likely contains:
  - `class StructurePredictor`: with an `__init__` that loads a model (e.g., if using HuggingFace Transformers, load the model and tokenizer for I-VILA). Possibly heavy, so we might want to load once and reuse (could be a singleton or module-level).
  - `def apply(document: Document) -> None`: which will analyze the Document’s content and add new layers:
    - It may iterate over `document.pages` or directly over `document.rows` (lines). For each, gather features (text content, position on page).
    - Feed through the layout classification model to get a label per line or per block.
    - Group lines with the same section label into a Section entity, identify title, authors, etc. If the model gives a probability distribution, use highest label.
    - For each label category, create an entity list in document.entities (e.g., all lines labeled “SectionHeading” become entries in `sections` layer; the first occurrence labeled “Title” becomes the `titles` layer content).
    - The predictor must also potentially use heuristic post-processing; e.g., combine consecutive lines of a section heading that were split, etc.
    - We will reference I-VILA’s known categories: likely "title", "abstract", "heading", "paragraph", "figure", "caption", "table", "footnote", "reference". We map these to our layers (some one-to-one, some we might collapse or split).
    
  **Origin references:** This corresponds to PaperMage’s integration of the I-VILA model, presumably implemented in a predictor class in *papermage/predictors/*. The parameter `ivila_predictor_path` in `CoreRecipe.__init__` ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=class%20CoreRecipe,layoutlm)) hints how it was configured. Our predictor will achieve the same end result. We will likely refer to the ACL paper or AllenAI docs for what I-VILA outputs to ensure we implement mapping correctly. In absence of their code, we rely on the concept that each text block gets a label and we use that. We can cite PaperMage’s approach: *“PaperMage’s layout predictor identifies segment types like titles, sections, etc., which we recreate here using the I-VILA model”*. Additionally, docling has a **“Coming soon: metadata extraction”** ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=Coming%20soon)) – once available, we could swap to that, but for now, our StructurePredictor stands in.

  **Docling usage:** If docling-ibm-models has an API (maybe a function like `docling.enrich(document, task="structure")`?), we would use it. More likely we directly use HF model. So this predictor might not call docling at all (aside from using positions from docling parse output). It’s custom code, but crucial for full feature parity.

- **`predictors/rtl_utils.py`:** Provides functions like:
  - `is_rtl(text: str) -> bool`: returns True if characters in text are mostly from an RTL script (Hebrew, Arabic, etc.). This could check Unicode ranges or use Python’s `unicodedata.bidirectional` property on characters.
  - `reorder_text_and_boxes(text: str, boxes: List[Box]) -> Tuple[str, List[Box]]`: if `is_rtl(text)` is True, this function will reorder the characters in `text` to logical order and correspondingly reorder the list of `Box` objects so that the first character in the new text corresponds to the first box on the right. We might use an existing library (like `python-bidi` and `arabic_reshaper` for Arabic shaping if needed). However, for Hebrew, simply reversing might suffice in many cases, but ideally apply the full bidi algorithm (for safety if numbers or LTR segments are inside).
  - `normalize_document(document: Document) -> None`: a convenience that goes through all text entities (or specifically low-level ones like tokens or rows) and applies `reorder_text_and_boxes` where appropriate. For example, for each row entity, check if its text is RTL; if yes, fix it in place. This way higher-level entities that consist of those spans automatically get corrected text. We must be careful that doing it at the row level might be ideal because if a row is RTL, all contained tokens will be reordered. If we did at token level it’s trickier. So likely approach: for each row, reorder its `.text` (if we store one) and swap the order of token entities within it.
  
  **Origin references:** PaperMage did not have this module, as it didn’t specifically handle RTL (to our knowledge). This is an entirely new addition. We include it because of the stated goal to support Hebrew. Therefore, no direct Papermage file link, but conceptually it aligns with ensuring the `Span` ordering is correct – spans in PaperMage were defined in terms of indices in `.symbols` ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=Each%20,about%20its%20contents%20and%20position)), so if we get `.symbols` correct, their spans naturally align. That’s what this helps ensure.
  
  **Docling usage:** Docling itself might not require modification for RTL, but we might look at how docling-parse orders characters: if it’s purely left-to-right by coordinate (which is typical), RTL text would come out reversed. So our utility fixes that. If in the future Docling addresses this internally, we can remove or simplify these functions. For now, `rtl_utils` works as a post-processor on Docling output.

- **`api_service.py`:** Contains FastAPI app setup:
  - We will use `from fastapi import FastAPI, UploadFile` etc. Define `app = FastAPI(title="PaperMage-Docling API", version=VERSION)`.
  - Endpoint example:
    ```python
    @app.post("/parse", response_model=DocumentJSONSchema)  # DocumentJSONSchema could be a Pydantic model or just Dict
    async def parse_document(file: UploadFile = File(...)):
        # read file contents
        pdf_bytes = await file.read()
        # write to a temp file or pass bytes to parser (docling-parse might accept stream)
        with open("temp.pdf", "wb") as f:
            f.write(pdf_bytes)
        doc = parser.parse("temp.pdf")
        return doc.to_json()
    ```
    (We can optimize by avoiding writing to disk if docling-parse allows parsing from bytes stream; the code snippet suggests `parser.load(path_or_stream=...)` ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=parser%20%3D%20DoclingPdfParser)) can accept a path or a stream, so we might pass `io.BytesIO(pdf_bytes)` directly.)
  - We may also have a simple `GET /health` or `/version` route to indicate service is up (docling-serve adds version in docs as per commit comment ([docling-project/docling-serve v0.5.0 on GitHub - NewReleases.io](https://newreleases.io/project/github/docling-project/docling-serve/release/v0.5.0#:~:text=NewReleases,ed851c9%20%29)); we can do similarly).
  - Optionally, a route `/preview` that returns an HTML preview or something (not necessary, but sometimes useful for debugging – perhaps out of scope).
  - Gradio: If we include, we might not integrate it into FastAPI (since Gradio launches its own server). Instead, we could put an if `__name__ == "__main__": import gradio as gr ...` to launch a demo. Or provide a separate script for it.
  
  **Origin references:** PaperMage did not have an out-of-the-box API server. However, the existence of docling-serve inspires this. We align partly with **docling-serve** design: it’s a FastAPI app wrapping similar functionality ([Docling Project · GitHub](https://github.com/docling-project#:~:text=If%20it%20has%20to%20do,API%20and%20distribute%20large%20jobs)). We can cite that docling-serve uses FastAPI for doc conversion and note we follow suit. Our `api_service.py` is effectively a lightweight version of docling-serve tailored to PaperMage output. It ensures that deployment is straightforward and that we can containerize easily. 

  Implementation details: We should use Uvicorn to run this. In Dockerfile, we might use `CMD ["uvicorn", "papermage_docling.api_service:app", "--host", "0.0.0.0", "--port", "8000"]`. In development, one can just do `uvicorn papermage_docling.api_service:app --reload`.

- **`tests/`:** Not actual code logic, but important to note:
  - We will reuse PaperMage’s test PDFs if possible. The original had at least `papermage.pdf` as a fixture ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=recipe%20%3D%20CoreRecipe,tests%2Ffixtures%2Fpapermage.pdf)). We have to ensure licensing, but since it’s likely a sample paper, should be fine for testing.
  - We may also include a small Hebrew PDF in tests (perhaps generate one with a sentence of Hebrew).
  - The tests will be standard pytest. We might define expected outcomes in JSON or known counts.
  - Example test in `test_parser.py`:
    ```python
    def test_page_count_and_text(tmp_path):
        parser = DoclingParser()
        doc = parser.parse("tests/fixtures/papermage.pdf")
        # The sample PDF has known number of pages, say 2
        assert len(doc.pages) == 2
        # Ensure the full text contains a known phrase from the PDF
        assert "PaperMage: A Unified Toolkit" in doc.symbols  # a phrase from the PDF’s title ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=What%20is%20a%20,str%3E%60.%20For%20example))
    ```
    This checks that we parsed the text correctly.
  - In `test_end_to_end.py`, we might load a reference JSON (perhaps stored in `tests/fixtures/papermage_expected.json`) and compare keys and basic values. Because exact equality might fail if float coordinates differ slightly, we’ll compare structural aspects (like same layers present, same number of entities in each, text content equality for key fields like title).
  - `test_rtl_processing()` (in test_predictors or separate) will create a dummy Document object with a Hebrew line out of order and run `rtl_utils` to see if it fixes it. Alternatively, parse a tiny PDF with Hebrew and ensure output text is not reversed.
  
  These tests ensure each file’s functionality: `parser_docling` (base parse), predictors (structure and rtl), and the integration (via API or direct call).

Each of these files will be documented with comments referencing the original approach. For instance, in `parser_docling.py` near the conversion of text, we’ll comment “# Corresponds to assembling Document.symbols and rows as in PaperMage’s Document construction ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=%7B%20,%5B...%5D)).” Likewise, in `structure_predictor.py`, we might cite PaperMage’s use of I-VILA for clarity. 

By dividing responsibilities in this file-by-file manner, we mirror the separation in PaperMage (which had magelib vs predictors, etc.) and make it easier to trace how an original PaperMage feature is now implemented. The mapping is summarized as: 

- *PaperMage `CoreRecipe` & parser code* → `parser_docling.DoclingParser` (uses docling-parse).
- *PaperMage `Rasterizer`* → integrated in `DoclingParser` via docling’s capabilities.
- *PaperMage `Predictors` (e.g. Layout, Entities)* → our `predictors/*.py` modules (using docling-core types or external models).
- *PaperMage `Document` class & Entities* → our internal representation and output JSON (constructed in parser and predictors).
- *PaperMage tests* → our tests (similar names, but adjusted for new implementation).

# Hebrew/RTL Support Plan

Handling right-to-left languages, particularly Hebrew, requires careful consideration at each stage of the pipeline to ensure the output is correct and natural. This section details how we will support RTL text:

**Bidi Text Reordering:** PDF extraction tools (including Docling’s) typically output text in the visual order they appear on the page, which for RTL scripts means reversed logical order. For example, a Hebrew sentence "בודק RTL טקסט" (meaning "testing RTL text") might be extracted as "טקסט RTL בודק" (letters in reverse order) if read left-to-right. To fix this, we will implement **bidirectional reordering** after extraction. The `rtl_utils.py` module provides the functionality: it will detect Hebrew/Arabic characters in a string and apply the Unicode Bidirectional Algorithm to reorder the characters to logical order. In practice, for pure Hebrew text, this amounts to reversing the string (since punctuation might still need special handling). We will use Python’s `bidilib` (if available) or a manual approach leveraging Unicode character properties. 

**Token Order within Spans:** When we reorder text, we must also reorder the corresponding `Span` indices and `Box` coordinates:
- **Spans:** In PaperMage, an `Entity.span` stores start and end indices into the `symbols` string ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=Each%20,about%20its%20contents%20and%20position)). If we simply reverse the Hebrew substring in `symbols`, the indices for that content remain the same (covering the same range of characters, now just in different order). So the primary work is to ensure `symbols` itself contains text in logical reading order. We will build `symbols` incrementally in the correct order. For RTL sections, instead of appending text as extracted (which might be backwards), we append the corrected text. Thus, spans indices are inherently correct because `symbols` is built correctly from the start. If necessary, for clarity, we may still adjust spans of lower-level entities. For example, if Docling gave us a word entity from index 100-104 that was "ABCD" (which is actually "DCBA" logically), after reordering `symbols[100:104]` now reads "ABCD" logically, and that span now corresponds to the correct word. So spans can stay the same numeric range, but the content in `symbols` at that range is different (corrected).
- **Bounding Boxes:** Each token or line has an associated bounding box (with x,y coordinates on the page) ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,spans)). For an English phrase, the first token’s box is leftmost; for Hebrew, the first token’s box is rightmost. After reordering the text, we need to ensure that the sequence of boxes matches the sequence of characters or tokens in the text. Our approach: when processing a line that is detected as RTL, we will sort the character or token boxes in descending order of their x-coordinate (since rightmost comes first) before associating them with the text characters. For entire line boxes (the `Row` entity box covering the line) we keep it as-is (it spans the whole line regardless of text direction). For token-level boxes, we likely store them already via Docling: docling-parse provides word bounding boxes. We will reorder those word boxes. Example: The Hebrew line has words [Word1, Word2, Word3] visually from right to left. Docling might output them in reading order (which hopefully is right-to-left for that line, but if it outputs left-to-right by coordinate, that’s already wrong order logically). If docling outputs by increasing x (which would be left-to-right), it would list [Word3, Word2, Word1]. We detect script and reorder to [Word1, Word2, Word3] based on coordinates. This ensures our Document.tokens list for that line goes in logical order.

**Maintaining Reading Direction Integrity:** We must do the above consistently at all levels:
- At the **line (row) level**, ensure that the text in `.symbols` for that row reads correctly. We will likely handle reordering at the line level as the atomic unit for bidi, since mixing direction within a line (e.g., English phrase in a Hebrew sentence) can be complex. Python’s bidi algorithm can handle mixed text, inserting Unicode bidi markers. We will integrate that so that, for example, "Algorithm 1 מתואר" (mixed English/Hebrew) is stored in a way that when displayed, "Algorithm 1" remains left-to-right within the right-to-left sentence. The JSON output will contain the actual characters possibly with directional markers (or we could choose to output the logical sequence which might look strange if printed naively but is correct logically). Likely we output text in logical order and rely on any consumer to render via bidi rules if needed.
- At the **token level**, after reordering a row’s text, we will also regenerate token spans for that row’s new text segment and assign boxes accordingly. This may involve mapping old indices to new (but since we are just reversing segments, this is manageable).
- We will add a metadata flag perhaps: For any Entity that has been reordered, set `entity.metadata["direction"] = "RTL"` for transparency. This is not required, but could be useful for debugging or if a consumer needs to know the direction of text. Docling’s planned language detection could populate `DoclingDocument.metadata.language` ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=Coming%20soon)); until then, we handle it.

**Example:** A Hebrew paragraph in the PDF will be processed as follows:
1. Docling extracts: text="תורה לוגיקה" (which is "logic order" reversed) and boxes for ["תורה", "לוגיקה"] but perhaps in opposite order.
2. `rtl_utils` sees Hebrew chars, reverses text to "לוגיקה תורה" (which is now the correct logical phrase "torah logika", meaning "logic order" in correct Hebrew).
3. It also swaps the two word boxes so that "לוגיקה" box comes first, "תורה" second.
4. The Document.symbols now gets "לוגיקה תורה".
5. The tokens layer for that line will have first token "לוגיקה" with its box, second "תורה" with its box. If we had not done this, the tokens would be flipped relative to their text.

**Span Normalization and Box Alignment:** One tricky scenario is when an Entity spans across lines or pages (e.g., a long sentence that continues onto the next line). PaperMage can handle discontinuous spans (an Entity can have multiple Span objects) ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=PaperMage%27s%20%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D1%83%D0%B5%D1%82%20%D0%B4%D0%B2%D0%B5%20%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5,%D0%B4%D0%B0%D0%B6%D0%B5%20%D0%BD%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%80%D0%B0%D0%B7%D0%BB%D0%B8%D1%87%D0%B8%D1%8F%20%D0%B2%20%D0%BC%D0%B0%D0%BA%D0%B5%D1%82%D0%B5)). For RTL text, if a sentence spans lines, each line we reorder individually. The concatenation of those lines in `symbols` will still end up correct, as each part was individually corrected. We just need to ensure that if an Entity covers multiple spans, we maintain each span’s internal order. We will test multi-line Hebrew paragraphs to confirm this.

Another aspect is **mixing LTR and RTL** at block level: For instance, section headings in English within an otherwise Hebrew document or vice versa. Our detection will operate line by line, so each line’s direction handled independently. This means in a Hebrew doc, an English heading line will be left untouched (since `is_rtl` will return False). That’s desirable (don’t reverse English). If a line is truly mixed (e.g., Arabic and English on one line), the bidi algorithm should place English words correctly among Arabic text. We will rely on robust libraries for that if possible. We must note that JSON output might not visually look like the original PDF for such mixed lines if viewed naively, but it will represent the correct underlying reading sequence.

**Docling’s Role in RTL:** Docling’s documentation does not explicitly mention RTL support. However, it does mention reading order is determined through the body tree structure ([Docling Document - Docling](https://docling-project.github.io/docling/concepts/docling_document/#:~:text=The%20reading%20order%20of%20the,each%20item%20in%20the%20tree)). For languages like Hebrew, we may need to override the default ordering. Our approach essentially post-processes Docling’s output to inject correct ordering, which is acceptable. If future versions of Docling add explicit bidi handling or language tagging, our plan is to detect that and disable our manual steps to avoid double processing. For instance, if docling-core’s `DoclingDocument` starts storing a direction for text items, we can utilize it. 

**Testing RTL:** To ensure our plan works, we will create a small test PDF with a known Hebrew sentence. We’ll parse it and manually verify the JSON contains the sentence in correct order (and not reversed). We will also compare coordinates: the first Hebrew character in logical order should have the rightmost x coordinate among the span’s boxes, etc., which we can assert. Additionally, we will test a mixed-direction case. 

**Limitations:** We should note a few limitations in this initial RTL support:
- If a document uses ligatures or diacritical marks (common in Arabic), proper display might need additional processing (like using arabic_reshaper). For Hebrew, diacritics (nikud) might be present; the Unicode text extraction might separate them. We will treat diacritics as part of the text and the bidi algorithm should handle them (they are combining marks, which should stay with their base letter).
- We assume that PDF text extraction yields individual characters such that reordering is feasible. In rare cases, PDFs might encode Hebrew in logical order already – then our reordering might actually mess it up (double reverse). To guard against this, we could apply a heuristic: if the text appears already in correct order (maybe by detecting if bigrams form valid Hebrew words), we should not reverse. However, this is complex. Instead, we might rely on the fact that almost all PDF extractors give visual order for RTL. We'll document this assumption. If we encounter a counter-case, an option could be a config flag to disable RTL fix if not needed.
- Multi-column Hebrew: If a page has two columns of Hebrew, docling’s reading order logic might output all text in one column then the other (which is correct). Our line-level reordering still applies within each line. That should be fine. We just must ensure we do not inadvertently mix content from different columns – but since we operate line by line, we won't.

In summary, the Hebrew/RTL support plan is to **intercept the output of the parsing stage and reorder text and layout for any identified RTL content**, thereby ensuring that from that point forward (predictors and final JSON) the data is as if it was correctly read RTL. This way, predictors like StructurePredictor, which might look at text content, will see Hebrew in normal order (which could slightly improve model accuracy, though models often can handle reversed since they see it as sequence of characters anyway – but it's better to feed logical order). 

We will maintain this approach in `rtl_utils` as an isolated component. If down the line Docling introduces a built-in solution (for example, using Tesseract's `orientation and script detection` for OCR or similar for text direction), we can compare results and possibly switch to that. Until then, our manual implementation assures that **the JSON output for Hebrew documents will be human-readable and logically ordered**, fulfilling the requirement of correct RTL handling.

# Testing & Validation

A comprehensive testing strategy will be employed to validate that the PaperMage-Docling implementation meets all requirements and does not regress on the original functionality. The testing approach covers unit tests for individual components, integration tests for end-to-end processing, and specific tests for RTL text handling and output fidelity.

**Test Suite Organization:**
The `tests/` directory is structured by functionality:
- `test_parser.py`: Unit tests for the parsing module (`parser_docling`).
- `test_predictors.py`: Unit tests for predictors (including structure classification and any others).
- `test_rtl.py`: Focused tests on RTL reordering (this can also be part of test_predictors or separate for clarity).
- `test_end_to_end.py`: Integration tests comparing full outputs to expected results.
- `test_api.py`: Tests the FastAPI service endpoints.

We use **pytest** to run all tests, leveraging fixtures for sample files. Continuous integration will run `pytest` on every commit (as indicated in development instructions ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=Unit%20testing)), we’ll integrate similarly).

**Regression Tests vs PaperMage Outputs:** A crucial validation method is to compare our output on known inputs with PaperMage’s output. We will create a small corpus of PDF documents for this:
- *papermage.pdf*: This is the fixture used in PaperMage’s own quick start ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=recipe%20%3D%20CoreRecipe,tests%2Ffixtures%2Fpapermage.pdf)), presumably a representative academic paper excerpt. We will run the original PaperMage (likely we can install `papermage==0.18.0`) on this PDF to generate a reference JSON. Our integration test will then parse the same PDF with our system and obtain JSON output. We'll then **diff the JSON structures**. We expect them to be largely identical. Minor differences might occur (for example, if coordinate rounding differs by a small amount, or if our model predictions differ slightly in classification).
  - We will write an assertion that all top-level keys (`symbols`, `entities`, `metadata`) exist. Then for each layer in `entities`, ensure that the count of entities matches. We will check specific content for key layers: e.g., the text of `title` layer entity should exactly equal in both outputs; same for `abstract`.
  - For numerical fields like coordinates, we may allow a small delta tolerance or convert to a uniform format (since floating-point differences of <0.5 pixel are negligible for our purposes).
  - If there are systematic differences (e.g., Docling might split a word differently than PDFPlumber did), we will document and decide if acceptable or if we need to adjust our processing to match (the goal is to match as closely as possible).
- Additional PDFs: We may include a PDF with complex layout (like two-column IEEE paper) to ensure our reading order doesn’t scramble content (PaperMage presumably handled multi-columns by analyzing PDF layout, which docling should also handle). We’ll validate that, for instance, the end-to-end test on such a PDF yields sections in the correct order.
- Edge cases: a one-page PDF that is purely an image (to test that our pipeline still runs and maybe outputs no text or triggers OCR if we had it – but since we are not focusing on OCR now, we just ensure it doesn’t crash). Also a PDF with only a title and no body, to see that we still produce a title entity, etc.

**RTL-specific Validation:** We will construct (or obtain) at least two test documents for RTL:
1. A simple PDF we create (e.g., using a tool to generate PDF from text) containing a known Hebrew sentence, maybe "שלום עולם" ("Hello World" in Hebrew) as a single line. This will be our ground truth case to see how docling-parse outputs it and how our `rtl_utils` fixes it. Our test will parse it and examine `doc.symbols` to ensure it equals "שלום עולם" (and not reversed). We will also verify that if we had tokens for each word, the order in `doc.tokens` corresponds to ["שלום", "עולם"] in that order.
2. A bilingual PDF, e.g., a line that says "Section 1 – מבוא" (mix of English "Section 1 – " and Hebrew "Introduction"). We expect the output `symbols` to have "Section 1 – מבוא" in that logical order, and that if this line is classified as a section heading, the text is correctly represented. We might create this via a word processor to ensure it's a single line in the PDF. The test will parse and confirm that substring "Section 1 – מבוא" appears exactly in `doc.symbols` (not, say, "מבוא 1 Section").
3. If possible, a real-world small Hebrew PDF (maybe a scientific article abstract in Hebrew or an OCR-ed text) to test on a realistic scenario. Even without an expected output, we can manually verify if needed.

**JSON Schema Validation:** We will use the docling-core’s `DoclingDocument` schema to validate our outputs as an extra check. In a test, after obtaining `output_json` from our parser, we can call:
```python
from docling_core.types import DoclingDocument
DoclingDocument.model_validate(output_json)
```
This will raise if our JSON doesn’t fit the schema (for example, missing required fields or wrong types). We expect to pass since we’ll include all fields. If something fails due to differences (like docling expects content in `texts` field rather than our layered approach), we will interpret results. We might not enforce full compliance if it contradicts PaperMage format, but it's a good sanity test for basic structure (ensuring no misnaming, etc.). This can be part of `test_end_to_end.py`.

**Performance Tests:** We will not have formal performance tests in CI (to avoid variability), but during development we will test parsing speed on a sample of large documents. We can have an optional test (marked with `@pytest.mark.performance` and skipped by default) that processes a 50-page PDF and asserts it finishes under, say, 10 seconds, just to catch any gross inefficiencies in our Python loops (Docling should handle it, but if our predictor is extremely slow, this might show up).

**Robustness Tests:** We will test unusual inputs:
- Corrupted PDF or nonexistent file: ensure `parser.parse` raises a clear exception or returns an error that the API can relay (likely a 400 response with message). For API tests, send a non-PDF file or invalid content and verify we handle it gracefully (maybe using pydantic validation or manual checks).
- Very large PDF (if we have one): ensure memory usage doesn’t blow up. This might be more of a manual test due to CI constraints.

**CI Integration:** We’ll set up GitHub Actions to run tests on Linux (and possibly Windows if needed to ensure cross-platform, since docling should work cross-platform). All tests must pass. We’ll also incorporate a linter/formatter (Docling and PaperMage both use black, we will too) to maintain code quality.

**Sample Test Cases:** Below are a few representative test scenarios with expected outcomes:

- *Test 1: Basic PDF Parsing* – Input: `tests/fixtures/papermage.pdf`. **Expectation:** `doc.symbols` is a non-empty string of length X; `len(doc.pages) == 5` (if the PDF has 5 pages, for example); `len(doc.tokens) > len(doc.words)` (assuming tokens include punctuation as separate, if that’s how we implement it; otherwise they may be equal or just test >0); `doc.metadata` contains at least keys like filename or creation date if we add that (not required, but docling might give PDF metadata, we could include it).
- *Test 2: Title and Sections Detection* – After running StructurePredictor on `papermage.pdf`, **Expectation:** `doc.titles[0].text` equals "PaperMage: A Unified Toolkit for Processing, Representing, and Manipulating Visually-..." (the known title from the example ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=What%20is%20a%20,str%3E%60.%20For%20example))). `doc.sections` is a list of length N (N sections in the paper). We might have known section headings from the PDF (like "Introduction", "Methods"), we assert those appear in `doc.sections[*].text`. This validates our predictor.
- *Test 3: Figure Extraction* – For a sample PDF with figures, ensure `doc.figures` length matches actual figure count. If the PDF has, say, 2 figures with captions, we expect `len(doc.captions) == 2` and each caption contains certain keywords or ends with a period. If we have images saved, verify the image files exist (if our pipeline saves them to disk or encodes as base64 in metadata).
- *Test 4: Hebrew Text Order* – Input: a PDF line "שלום עולם". **Expectation:** In the JSON output (or `Document.symbols`), the substring "שלום עולם" appears exactly (not reversed). Moreover, split by space, the order is ["שלום","עולם"]. We can enforce: `doc.tokens[0].text == "שלום"` and `doc.tokens[1].text == "עולם"` if those are the first two tokens in document (assuming that PDF had only that text). If docling had extracted as "עולם שלום" originally, our test would catch if we failed to reorder.
- *Test 5: Mixed Direction* – Input: "Hello שלום". **Expectation:** We decide how to handle; likely that becomes "Hello שלום" in output (which if printed will show "Hello " then "שלום" correctly). We could check that the English word "Hello" appears in the beginning of that combined string, and "שלום" at the end. The complexity of verifying bidi rendered order might be beyond a simple test; but we can at least ensure no characters are lost or extra spaces introduced.

- *Test 6: API JSON Response* – Using FastAPI’s TestClient, do:
  ```python
  response = client.post("/parse", files={"file": ("doc.pdf", open("tests/fixtures/papermage.pdf","rb"), "application/pdf")})
  assert response.status_code == 200
  data = response.json()
  assert "symbols" in data and "entities" in data
  assert len(data["entities"]["pages"]) == 5  # for example
  ```
  This ensures the web endpoint returns the same structure. We might also test that sending an invalid file returns a 422 or 400 with an error message.

**Regression vs. Non-regression Tolerance:** It’s important to define what differences from PaperMage are acceptable:
- If our output has *additional* detail that doesn’t break format (e.g., we provide structured table cells in metadata whereas PaperMage just had a table as one block), that could be acceptable or even beneficial, as long as it doesn’t confuse consumers. But as a conservative approach, we will not add fields in the main JSON structure that weren’t there. If we do add, it might go into `doc.metadata` or under an optional key.
- If the ML model predicts slightly differently (say PaperMage’s model labeled a line as "Section" but our model or approach didn’t), this is a functional difference. We aim to minimize these by using the same model weights if possible. If differences occur, we decide based on importance: e.g., if our predictor misses a section heading, that’s a regression we should fix (maybe our threshold is off). 
- Minor coordinate differences or tokenization differences (like splitting of hyphenated words) may be tolerable as long as they don’t break usage. We will document any such minor differences.

**Test Data and Coverage:** We are covering typical research papers (since that’s PaperMage’s domain). Additionally:
- We will test on a non-scientific PDF (like a simple contract or form) to see if anything breaks assumptions (shouldn’t – our system will still output tokens and lines, albeit the structure predictor might classify things as paragraph or unknown, which is fine).
- Multi-language PDF (like one page English, another page Hebrew) to ensure our pipeline can handle both simultaneously. Docling-parse would output all text, and our RTL fix would only change the Hebrew parts. We expect no issues since we check per line.
- We should also ensure our system doesn’t crash or hang on tricky PDFs (like ones with lots of drawing elements or weird encodings). This is more fuzz testing; for now, we rely on Docling’s robustness (and indeed docling-parse is meant for programmatic PDFs, it might not parse malformed ones well, but we can’t fix PDF parsing beyond what docling provides).

Through this testing strategy, we will achieve high confidence that PaperMage-Docling meets its design goals. We will maintain some of PaperMage’s own tests logic where applicable (for example, if PaperMage had tests for verifying cross-layer linking, we should include similar tests: e.g., pick a random sentence from `doc.sentences` and ensure all its tokens indeed appear in `doc.tokens` and match the text when concatenated – this tests the internal consistency of spans).

IMPORTANT - the tests shall be equivlant to the docling-parser in output of the visualized pdf parsing and analysis and also take inpire form the original tests of the papermage library!!! - https://github.com/allenai/papermage/tree/main/tests

Finally, beyond automated tests, we will do **manual validation** on a handful of documents, especially focusing on visual correctness:
- Render output (maybe using PaperMage’s visualizer or some custom small script) to see that pages, boxes align on an image of the PDF. This is more for our satisfaction that nothing is wildly off in layout mapping.

By thoroughly testing from unit level up to full system outputs, including the critical comparison with known PaperMage outputs, we ensure the reimplementation is reliable and ready to replace the original.

# Deployment & Maintenance

Deploying the PaperMage-Docling system will leverage modern containerization and standard server frameworks, making it straightforward to integrate into various environments (development, staging, production). Additionally, a maintenance plan will ensure the project stays up-to-date with the evolving Docling stack and addresses future needs.

**Docker Deployment:** We will provide a Dockerfile that encapsulates the application and its dependencies. The base image will be a Python 3.11 environment. We will install:
- The required system packages for docling-parse. Docling-parse may need build tools; however, since it is available via pip (with prebuilt wheels for many platforms), we likely can just `pip install docling docling-core docling-parse docling-serve` inside the container. To be safe, we might need system libraries like `poppler` or `libxml` depending on docling’s internals (docling-parse’s README doesn’t list explicit system deps, it might bundle PDFium via Pybind11).
- Our package (the context will copy our code into the image and run `pip install .` or `poetry install` depending on our packaging).
- Any extras like the I-VILA model weights: If using HuggingFace, we might either have the model download at runtime (first use) or we could add steps in Dockerfile to download the model into a cache directory. For reproducibility, we might bake it in (to avoid reliance on external download at runtime, which could slow first request).
  
The Dockerfile will expose port 8000 and set the entrypoint to the Uvicorn command (as described earlier). We will also include in README usage instructions:
```
docker build -t papermage-docling .
docker run -p 8000:8000 papermage-docling
```
Then hitting `http://localhost:8000/docs` will show the Swagger UI (FastAPI auto docs), where one can test the `/parse` endpoint with a PDF. We won’t mention docling-serve in usage to avoid confusion, but under the hood our container is quite similar to running docling-serve (just outputting a different JSON format).

**FastAPI Uvicorn Details:** We choose Uvicorn as the ASGI server (lightweight and suitable for this use-case). We'll configure it for production in Docker (e.g., workers count could be set via env var if needed, but one worker might be fine if using async, or multiple for CPU-bound if many concurrent users – since parsing PDF is CPU heavy, a few workers might be good on a multi-core server). FastAPI’s robustness covers concurrency and error handling, which we’ll utilize (if `parser.parse` throws, FastAPI will return 500 by default; we might catch predictable errors to return 400 for bad input).

**Gradio Interface for UI Testing:** For easier experimentation and demonstration (especially for non-technical stakeholders), we will include a Gradio app. This might not live in the main container by default, but we can have a separate script or just instructions to run Gradio locally. For instance, `gradio_app.py` (not listed above, but we can create on the fly if needed) which uses our parser:
```python
import gradio as gr
from papermage_docling import DoclingParser

parser = DoclingParser()

def process_pdf(file):
    doc = parser.parse(file.name)
    # perhaps return the JSON or a formatted summary
    return doc.to_json()

gr.Interface(fn=process_pdf, inputs="file", outputs="json").launch()
```
This will allow uploading a PDF and seeing the JSON output in the browser. In the PRD context, we mention this as a convenience for UI testing. It’s not a core deployment component but can be used by developers or QA to manually verify outputs without writing code or using curl. 

**Continuous Integration (CI):** We will set up CI (likely GitHub Actions as in PaperMage ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=272%20Commits))) to run tests and linters on each push:
- A workflow YAML will install our package (and docling dependencies) in a fresh environment, run `pytest`, and possibly `flake8` or similar. We’ll also incorporate `black --check` for formatting and `mypy` for type checking if we decide to use type hints thoroughly (Docling uses Pydantic v2 which is dataclass-like, type checking could help).
- All tests must pass for merges. This ensures we don’t inadvertently break something with future modifications.

**Version Control & Releases:** We will version our package (starting at 0.1.0 perhaps) and use semantic versioning. If integrated into an existing project, maybe they will tag it as part of that. We might publish it to a private PyPI or keep within codebase. Not strictly in PRD scope, but we mention for completeness that maintenance includes version bumps when Docling libraries update significantly.

**Syncing with Docling Updates:** Docling is an active project (with frequent releases as seen: docling-core v2.26.1 was Apr 11, 2025 ([GitHub - docling-project/docling-core: A python library to define and validate data types in Docling.](https://github.com/DS4SD/docling-core#:~:text=Releases%2071))). To avoid breaking changes:
- We will pin dependency versions in `pyproject.toml` (or requirements) to the latest known working ones (e.g., docling==0.x, docling-core==2.y, etc. that we tested with). This ensures stability. We will regularly test our pipeline with newer versions of Docling in a branch or CI matrix. For example, we can have a cron job in CI that runs tests with the latest docling-core/parse to see if anything fails.
- If Docling introduces changes in JSON schema or capabilities (like a new field or different default output), we will update our mapping logic accordingly. We plan to monitor Docling’s release notes (maybe subscribing to the repo or RSS of releases).
- In particular, if Docling implements features that overlap with our custom code (like if docling gets its own layout classifier or RTL support), we may deprecate parts of our implementation in favor of theirs. We will then bump our version (potentially major if it changes outputs) or behind a flag to toggle old/new behavior. For now, those would be future enhancements.

**Model Maintenance:** If using the I-VILA model or any external ML model, we need to maintain compatibility. That model is static (trained once). If a newer model (say Docling’s team releases a new model for document layout) comes that is superior, we may switch. That would be a planned improvement. It might require converting output labels to our format.

**Logging & Monitoring:** In production, we might integrate logging (via Python logging) to record usage stats: e.g., log an info message for each parse request including time taken, number of pages, etc. This helps monitor performance and load. We could also add a Prometheus endpoint easily via FastAPI instrumentation, but that might be overkill for now. At least, logs will help identify if any document fails parsing or takes too long.

**Documentation and Support:** The README will include instructions for usage (both as a library and via API). We will likely have examples similar to PaperMage’s:
```python
from papermage_docling import CoreRecipe
doc = CoreRecipe().run("myfile.pdf")
print(doc.sections[0].text)
```
with notes on installation. Also, document how to run the server and use the endpoint. We assume users of PaperMage will adapt quickly if they see the similarities.

**Maintenance Personnel:** Ideally the team maintaining this includes those familiar with both PaperMage and Docling. They will need to test whenever Docling or this library is updated. It might be useful to write a small *expected output library* of some PDFs and a script to compare outputs across versions (not just in tests but as a maintenance tool).

**Future Plans (beyond initial deployment):** 
- We will track upcoming Docling features (like metadata extraction for title/authors ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=Coming%20soon))) and plan to integrate them when mature, possibly removing our custom code. Similarly, Docling’s *docling-serve* may gain features (like distributed processing) that we could adopt or at least ensure our deployment is compatible (for example, docling-serve might introduce a job queue microservice – if we needed huge scale, we could either use their service directly and convert outputs, or adapt similar approach).
- Monitor issues reported by users. Since PaperMage original is not maintained, users might come to this project with requests or bug reports. We will use a public issue tracker to manage those.
- Keep an eye on PDF parsing improvements in general (like if PDFPlumber updates or if some bug in docling-parse is discovered affecting extraction, etc.).

**Rolling Out Replacement:** If this is to replace an existing PaperMage in production somewhere (e.g., within Semantic Scholar’s pipeline or a research project), we will do a phased rollout:
1. Run both PaperMage and PaperMage-Docling in parallel on a sample of documents, compare outputs thoroughly (this we largely do in testing).
2. Perhaps deploy the new one as a beta API endpoint, let internal users test.
3. Once confirmed, switch over fully to the new system.

**Backup Plan:** Should any severe issue be discovered in the new implementation (say some PDF that PaperMage handled well but our system fails on due to a bug), we will have the option to fall back to the old PaperMage for those cases while we fix the bug. This implies we won’t immediately deprecate the old pipeline until the new one is battle-tested. In code, this could mean we keep an option to call the old code (if installed) if needed. However, given thorough testing, we expect not to need this.

In conclusion, from a DevOps perspective, the product will be delivered as:
- a Python package (for direct use or embedding into other code),
- a Docker container (for easy API deployment),
- accompanied by documentation and example notebooks perhaps (like PaperMage had a quick_start Jupyter notebook – we can provide an updated one showing usage of our library on an example PDF, making sure the output is as expected).

This deployment and maintenance plan ensures that the PaperMage-Docling implementation is not just a static re-code, but a living project that can grow and adapt, with robust infrastructure around it for testing and delivery. By using containers and CI, we align with modern best practices, facilitating reliable releases and easier handoff to operations teams.

# References

1. **AllenAI PaperMage Repository (README)** – *Describes PaperMage’s functionality and usage.* GitHub: *allenai/papermage* ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=Quick%20start)) ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,words%27%2C%20%27sentences%27%2C%20%27blocks%27%2C%20%27vila_entities%27%2C%20%27titles))

2. **AllenAI PaperMage Documentation (README continued)** – *Details on Document layers, spans, and boxes.* ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=Each%20,about%20its%20contents%20and%20position)) ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=PaperMage%27s%20%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D1%83%D0%B5%D1%82%20%D0%B4%D0%B2%D0%B5%20%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5,%D0%B4%D0%B0%D0%B6%D0%B5%20%D0%BD%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%80%D0%B0%D0%B7%D0%BB%D0%B8%D1%87%D0%B8%D1%8F%20%D0%B2%20%D0%BC%D0%B0%D0%BA%D0%B5%D1%82%D0%B5))

3. **PaperMage Habr Blog (Russian, 2024)** – *Explains PaperMage design (Magelib, Predictors, Recipes) with code excerpts.* ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=%D0%92%20Papermage%20%D0%BC%D0%BE%D0%B6%D0%BD%D0%BE%20%D0%B2%D1%8B%D0%B4%D0%B5%D0%BB%D0%B8%D1%82%D1%8C%20%D1%82%D1%80%D0%B8,%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D1%8B%D1%85%20%D0%BA%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82%D0%B0)) ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=%D0%91%D0%B0%D0%B7%D0%BE%D0%B2%D1%8B%D0%B5%20%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D1%8B%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85))

4. **PaperMage Quick Start Example** – *Snippet of using CoreRecipe to parse a PDF.* ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=,first%20time%20from%20a%20PDF)) ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=def%20from_pdf%28self%2C%20pdf%3A%20Path%29%20,doc%20%3D%20self.parser.parse%28input_pdf_path%3Dpdf))

5. **PaperMage JSON Output Example** – *Illustration of `Document.to_json()` output structure.* ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=import%20json%20with%20open%28%27filename,to_json%28%29%2C%20f_out%2C%20indent%3D4)) ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=%7B%20,%5B...%5D))

6. **Docling Project Overview** – *Docling key repositories and descriptions (docling, core, parse, serve).* ([Docling Project · GitHub](https://github.com/docling-project#:~:text=%2A%20docling%20%20,generation%20for%20RAG%2C%20finetuning%2C%20etc)) ([Docling Project · GitHub](https://github.com/docling-project#:~:text=If%20it%20has%20to%20do,API%20and%20distribute%20large%20jobs))

7. **Docling README (Features)** – *Highlights Docling’s multi-format parsing, advanced PDF understanding, and unified DoclingDocument.* ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=Features)) ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=,Haystack%20for%20agentic%20AI))

8. **Docling-Parse Documentation** – *Describes docling-parse capabilities (text, paths, images with coordinates) and usage.* ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=Simple%20package%20to%20extract%20text%2C,extracted%20paths%20and%20bitmap%20resources)) ([GitHub - docling-project/docling-parse: Simple package to extract text with coordinates from programmatic PDFs](https://github.com/docling-project/docling-parse#:~:text=from%20docling_core,pdf_parser%20import%20DoclingPdfParser%2C%20PdfDocument))

9. **Docling-Core Documentation** – *Defines DoclingDocument schema and data model via Pydantic.* ([GitHub - docling-project/docling-core: A python library to define and validate data types in Docling.](https://github.com/DS4SD/docling-core#:~:text=,for%20the%20full%20JSON%20schema))

10. **Docling Document Concept (Docs)** – *Explains DoclingDocument content structure (texts, tables, pictures, body tree for reading order).* ([Docling Document - Docling](https://docling-project.github.io/docling/concepts/docling_document/#:~:text=A%20%60DoclingDocument%60%20exposes%20top,are%20stored%20in%20these%20fields)) ([Docling Document - Docling](https://docling-project.github.io/docling/concepts/docling_document/#:~:text=The%20reading%20order%20of%20the,each%20item%20in%20the%20tree))

11. **Docling “Coming Soon” Features** – *Notes planned metadata extraction (title, authors, references, language) in Docling’s README.* ([GitHub - docling-project/docling: Get your documents ready for gen AI](https://github.com/DS4SD/docling#:~:text=Coming%20soon))

12. **Docling-Serve GitHub** – *FastAPI wrappers for Docling as a service (commit notes about FastAPI docs).* ([docling-project/docling-serve v0.5.0 on GitHub - NewReleases.io](https://newreleases.io/project/github/docling-project/docling-serve/release/v0.5.0#:~:text=NewReleases,ed851c9%20%29))

13. **I-VILA Model (PaperMage Predictor)** – *Referenced via AllenAI’s predictor path used in CoreRecipe (for document layout classification).* ([Демистифицируем парсинг PDF: конвейерная обработка / Хабр](https://habr.com/ru/companies/otus/articles/835930/#:~:text=class%20CoreRecipe,layoutlm))

14. **PaperMage Logging & Testing** – *Usage of pytest in PaperMage dev workflow.* ([GitHub - allenai/papermage: library supporting NLP and CV research on scientific papers](https://github.com/allenai/papermage#:~:text=Unit%20testing))

15. **Docling-Core Release Info** – *Shows recency of docling-core releases (v2.26.1 in April 2025), indicating active maintenance.* ([GitHub - docling-project/docling-core: A python library to define and validate data types in Docling.](https://github.com/DS4SD/docling-core#:~:text=Releases%2071))

16. **FastAPI Documentation** – *General reference for building file upload endpoints and running Uvicorn (implicit from context, not directly cited above).* (FastAPI official docs)

17. **Unicode Bidirectional Algorithm** – *Technical reference for handling RTL text ordering (UAX #9).* (Unicode Standard Annex #9)

18. **Python bidirectional text libraries** – *Potential tools for implementing RTL support (e.g., python-bidi).*

19. **AllenAI PaperMage ACL Paper (2023)** – *“PaperMage: A Unified Toolkit...” for background on motivation (cited for conceptual understanding of VILA, not directly in text above).* ([[PDF] PaperMage: A Unified Toolkit for Processing, Representing, and ...](https://aclanthology.org/2023.emnlp-demo.45.pdf#:~:text=,We%20show))

20. **IBM Docling Technical Report (arXiv 2024)** – *Documentation of Docling approach (for reference on design, not directly cited in text).*
